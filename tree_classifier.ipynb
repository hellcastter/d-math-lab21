{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Decision Tree Classifier \"\"\"\n",
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    \"\"\" Node for a decision tree \"\"\"\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, gini: float):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.gini = gini\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0.0\n",
    "\n",
    "        self.left: Node | None = None\n",
    "        self.right: Node | None = None\n",
    "\n",
    "        self.class_number: int | None = None\n",
    "\n",
    "    def detect_class(self):\n",
    "        \"\"\" Detect to which class node is \"\"\"\n",
    "        self.class_number = np.bincount(self.y).argmax()\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    \"\"\" Decision tree \"\"\"\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "        self.root = None\n",
    "\n",
    "\n",
    "    def gini(self, classes: np.ndarray) -> float:\n",
    "        \"\"\"A Gini score gives an idea of how good a split is by how mixed the\n",
    "        classes are in the two groups created by the split.\n",
    "        \n",
    "        A perfect separation results in a Gini score of 0,\n",
    "        whereas the worst case split that results in 50/50\n",
    "        classes in each group result in a Gini score of 0.5\n",
    "        (for a 2 class problem)\n",
    "\n",
    "        O(N^2)\n",
    "        \n",
    "        Args:\n",
    "            classes (np.ndarray): list of used classes\n",
    "\n",
    "        Returns:\n",
    "            float: gini index\n",
    "\n",
    "        >>> Tree.gini(np.array([1, 2, 3, 2, 1]))\n",
    "        0.6399999999999999\n",
    "        \"\"\"\n",
    "        gini_sum = 0\n",
    "        number_of_classes = len(classes)\n",
    "\n",
    "        for group_class in np.unique(classes, return_counts=True)[1]:\n",
    "            gini_sum += (group_class / number_of_classes) ** 2\n",
    "\n",
    "        return 1 - gini_sum\n",
    "\n",
    "\n",
    "    def split_data(self, X: np.ndarray, y: np.ndarray) -> tuple[int, float, float]:\n",
    "        \"\"\"Test all the possible splits in O(N*F) where N in number of samples\n",
    "        and F is number of features\n",
    "        in this case O(N * FlogF). We sort features to get median of two neighbor. \n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): training data\n",
    "            y (np.ndarray): training answers\n",
    "\n",
    "        Returns:\n",
    "            tuple[int, float, float]: index of feature, threshold and gini\n",
    "\n",
    "        >>> Tree.split_data(\n",
    "        ...     np.array([[10, 7], [2, 10], [5, 7]]),\n",
    "        ...     np.array([1, 0, 1])\n",
    "        ... )\n",
    "        (0, 3.5, 0.0)\n",
    "        \"\"\"\n",
    "        number_of_features = len(X[0])\n",
    "        number_of_classes = y.size\n",
    "\n",
    "        index = 0\n",
    "        threshold = 0.0\n",
    "        lowest_gini = np.Inf\n",
    "\n",
    "        # for all features\n",
    "        for class_idx in range(number_of_features):\n",
    "            # create heapq of feature column\n",
    "            active_group = []\n",
    "\n",
    "            for feature in X:\n",
    "                element = feature[class_idx]\n",
    "                heapq.heappush(active_group, element)\n",
    "\n",
    "            # we have to get mean of two neighbor elements\n",
    "            # 1 and 2, 2 and 3 and so on...\n",
    "            # so we need len(active_group) - 1 iterations\n",
    "            for _ in range(len(active_group) - 1):\n",
    "                # mean of two smallest elements\n",
    "                new_threshold = sum(heapq.nsmallest(2, active_group)) / 2\n",
    "                heapq.heappop(active_group)\n",
    "\n",
    "                # divide by left and right tree info\n",
    "                under_threshold = X[:, class_idx] < new_threshold\n",
    "                left_tree_y = y[under_threshold]\n",
    "                right_tree_y = y[~under_threshold]\n",
    "\n",
    "                # calc gini for children\n",
    "                left_gini = self.gini(left_tree_y)\n",
    "                right_gini = self.gini(right_tree_y)\n",
    "\n",
    "                left_nodes_count = len(left_tree_y)\n",
    "\n",
    "                # gini for this node\n",
    "                # i/m * Gini_left + (m-i)/m * Gini_right\n",
    "                gini = left_gini * (left_nodes_count / number_of_classes) +\\\n",
    "                    right_gini * (1 - (left_nodes_count / number_of_classes))\n",
    "\n",
    "                if gini < lowest_gini:\n",
    "                    lowest_gini = gini\n",
    "                    index = class_idx\n",
    "                    threshold = new_threshold\n",
    "\n",
    "        return index, threshold, lowest_gini\n",
    "\n",
    "\n",
    "    def build_tree(self, X: np.ndarray, y: np.ndarray, depth=0) -> Node | None:\n",
    "        \"\"\"create a root node\n",
    "        recursively split until max depth is not exceeded\n",
    "\n",
    "        O(N * FlogF + )\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): training data\n",
    "            y (np.ndarray): training answers\n",
    "            depth (int, optional): max depth of tree. Defaults to 0.\n",
    "\n",
    "        Returns:\n",
    "            Node | None: root node of decision tree\n",
    "        \"\"\"\n",
    "        if self.max_depth and depth > self.max_depth:\n",
    "            return None\n",
    "\n",
    "        index, threshold, gini = self.split_data(X, y)\n",
    "\n",
    "        if index is None:\n",
    "            return None\n",
    "\n",
    "        node = Node(X, y, gini)\n",
    "        node.feature_index = index\n",
    "        node.threshold = threshold\n",
    "        node.detect_class()\n",
    "\n",
    "        under_threshold = X[:, index] < threshold\n",
    "\n",
    "        # left child data\n",
    "        left_X = X[under_threshold]\n",
    "        left_y = y[under_threshold]\n",
    "\n",
    "        # right child data\n",
    "        right_X = X[~under_threshold]\n",
    "        right_y = y[~under_threshold]\n",
    "\n",
    "        # can't divide on left and right\n",
    "        if right_y.size == 0 or left_y.size == 0:\n",
    "            return node\n",
    "\n",
    "        node.left = self.build_tree(left_X, left_y, depth=depth + 1)\n",
    "        node.right = self.build_tree(right_X, right_y, depth=depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"basically wrapper for build tree / train\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): training data\n",
    "            y (np.ndarray): training answers\n",
    "        \"\"\"\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "\n",
    "    def predict_one(self, test: np.ndarray) -> int | None:\n",
    "        \"\"\"Predict which class will test data have\n",
    "\n",
    "        Args:\n",
    "            test (np.ndarray): test data\n",
    "\n",
    "        Returns:\n",
    "            int: class index\n",
    "        \"\"\"\n",
    "        root = self.root\n",
    "\n",
    "        if root is None:\n",
    "            print(\"Train your decision tree at first\")\n",
    "            return None\n",
    "\n",
    "        while True:\n",
    "            feature = root.feature_index\n",
    "\n",
    "            if test[feature] < root.threshold:\n",
    "                if root.left is None:\n",
    "                    return root.class_number\n",
    "\n",
    "                root = root.left\n",
    "            else:\n",
    "                if root.right is None:\n",
    "                    return root.class_number\n",
    "\n",
    "                root = root.right\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> list[int | None]:\n",
    "        \"\"\"traverse the tree while there is a child\n",
    "        and return the predicted class for it, \n",
    "        note that X_test can be a single sample or a batch\n",
    "\n",
    "        Args:\n",
    "            X_test (np.ndarray): test data\n",
    "\n",
    "        Returns:\n",
    "            list[int | None]: list of classes\n",
    "        \"\"\"\n",
    "        return [self.predict_one(test) for test in X_test]\n",
    "\n",
    "    def evaluate(self, X_test: np.ndarray, y_test: np.ndarray) -> float:\n",
    "        \"\"\"return accuracy\n",
    "\n",
    "        Args:\n",
    "            X_test (np.ndarray): test data\n",
    "            y_test (np.ndarray): answers\n",
    "\n",
    "        Returns:\n",
    "            float: accuracy of prediction\n",
    "        \"\"\"\n",
    "        return sum(self.predict(X_test) == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris # (120, 4)\n",
    "from sklearn.datasets import load_wine # (142, 13)\n",
    "from sklearn.datasets import load_breast_cancer # (455, 30)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "# divide dataset to training and test data\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "tree = DecisionTreeClassifier(10)\n",
    "tree.fit(X, y) # it takes ~3s to train (455, 30) data\n",
    "\n",
    "print( tree.evaluate(X_test, y_test) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f79c9b16f38ffcb775a40230065153e5698d2449f4affda733ae3cb98dd9ffb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
